{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Deterministic Policy Gradient Model for Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to have installed the UnityEnvironment and the dependencies.  \n",
    "You can find the instructions for this in the [Udacity Deep Re-inforcement Learning Github](https://github.com/udacity/deep-reinforcement-learning#dependencies).\n",
    "\n",
    "\n",
    "I have cut and pasted these below, but if they don't work, refer back to the original for updated instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "To set up your python environment to run the code in this repository, follow the instructions below.\n",
    "\n",
    "1. Create (and activate) a new environment with Python 3.6.\n",
    "\n",
    "\t- __Linux__ or __Mac__: \n",
    "\t```bash\n",
    "\tconda create --name drlnd python=3.6\n",
    "\tsource activate drlnd\n",
    "\t```\n",
    "\t- __Windows__: \n",
    "\t```bash\n",
    "\tconda create --name drlnd python=3.6 \n",
    "\tactivate drlnd\n",
    "\t```\n",
    "\t\n",
    "2. Follow the instructions in [this repository](https://github.com/openai/gym) to perform a minimal install of OpenAI gym.  \n",
    "\t- Next, install the **classic control** environment group by following the instructions [here](https://github.com/openai/gym#classic-control).\n",
    "\t- Then, install the **box2d** environment group by following the instructions [here](https://github.com/openai/gym#box2d).\n",
    "\t\n",
    "3. Clone the repository (if you haven't already!), and navigate to the `python/` folder.  Then, install several dependencies.\n",
    "```bash\n",
    "git clone https://github.com/udacity/deep-reinforcement-learning.git\n",
    "cd deep-reinforcement-learning/python\n",
    "pip install .\n",
    "```\n",
    "\n",
    "4. Create an [IPython kernel](http://ipython.readthedocs.io/en/stable/install/kernel_install.html) for the `drlnd` environment.  \n",
    "```bash\n",
    "python -m ipykernel install --user --name drlnd --display-name \"drlnd\"\n",
    "```\n",
    "\n",
    "5. Before running code in a notebook, change the kernel to match the `drlnd` environment by using the drop-down `Kernel` menu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name= \"Reacher.app\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
